{
    "summary": "The GoT framework is a Python 3.8+ language model that solves sorting problems, outputs JSON graphs, and provides detailed instructions for usage with real-world examples in the examples directory. Users are encouraged to star the repository, ask questions, provide feedback, and cite the reference when using it in other projects.",
    "details": [
        {
            "comment": "Installation instructions for the Graph of Thoughts (GoT) framework. Requires Python 3.8 or newer and can be installed directly from PyPI using pip.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/README.md\":0-19",
            "content": "# Graph of Thoughts (GoT)\n<p align=\"center\">\n  <img src=\"paper/pics/preview.svg\">\n</p>\nThis is the official implementation of [Graph of Thoughts: Solving Elaborate Problems with Large Language Models](https://arxiv.org/pdf/2308.09687.pdf).  \nThis framework gives you the ability to solve complex problems by modeling them as a Graph of Operations (GoO), which is automatically executed with a Large Language Model (LLM) as the engine.  \nThis framework is designed to be flexible and extensible, allowing you to not only solve problems using the new GoT approach, but also to implement GoOs resembling previous approaches like CoT or ToT.\n## Setup Guide\nIn order to use this framework, you need to have a working installation of Python 3.8 or newer.\n### Installing GoT\nBefore running either of the following two installation methods, make sure to activate your Python environment (if any) beforehand.  \nIf you are a user and you just want to use `graph_of_thoughts`, you can install it directly from PyPI:\n```bash\npip install graph_of_thoughts"
        },
        {
            "comment": "This code provides instructions for installing and configuring an LLM (Language Model) to use the Graph of Thoughts framework. The code also shows a quick start example for solving the sorting problem with a list of 32 numbers using a CoT-like approach, assuming the setup guide has been followed.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/README.md\":20-47",
            "content": "```\nIf you are a developer and you want to modify the code, you can install it in editable mode from source:\n```bash\ngit clone https://github.com/spcl/graph-of-thoughts.git\ncd graph-of-thoughts\npip install -e .\n```\n### Configuring the LLM\nIn order to use the framework, you need to have access to an LLM.\nPlease follow the instructions in the [Controller README](graph_of_thoughts/controller/README.md) to configure the LLM of your choice.\n## Quick Start\nThe following code snippet shows how to use the framework to solve the sorting problem for a list of 32 numbers using a CoT-like approach.  \nMake sure you have followed the [Setup Guide](#setup-guide) before running the code.\n```python\nfrom examples.sorting.sorting_032 import SortingPrompter, SortingParser, utils\nfrom graph_of_thoughts import controller, language_models, operations\n# Problem input\nto_be_sorted = \"[0, 2, 6, 3, 8, 7, 1, 1, 6, 7, 7, 7, 7, 9, 3, 0, 1, 7, 9, 1, 3, 5, 1, 3, 6, 4, 5, 4, 7, 3, 5, 7]\"\n# Create the Graph of Operations\ngop = operations.GraphOfOperations()"
        },
        {
            "comment": "This code generates a graph of thoughts using the GoT approach. It appends operations to generate, score (using num_errors function), and ground truth (using test_sorting function). It then initializes a language model with an API key from config.json and creates a controller with given parameters. Finally, it runs the controller and outputs the graph in JSON format. The example problem input is provided for usage.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/README.md\":48-82",
            "content": "gop.append_operation(operations.Generate())\ngop.append_operation(operations.Score(scoring_function=utils.num_errors))\ngop.append_operation(operations.GroundTruth(utils.test_sorting))\n# Configure the Language Model (Assumes config.json is in the current directory with OpenAI API key)\nlm = language_models.ChatGPT(\"config.json\", model_name=\"chatgpt\")\n# Create the Controller\nctrl = controller.Controller(\n  lm, \n  gop, \n  SortingPrompter(), \n  SortingParser(),\n  # The following dictionary is used to configure the initial thought state\n  {\n    \"original\": to_be_sorted,\n    \"current\": \"\",\n    \"method\": \"cot\"\n  }\n)\n# Run the Controller and generate the output graph\nctrl.run()\nctrl.output_graph(\"output_cot.json\")\n```\nTo run the more sophisticated GoT approach, you can use the following code snippet.\n```python\nfrom examples.sorting.sorting_032 import SortingPrompter, SortingParser, got, utils\nfrom graph_of_thoughts import controller, language_models, operations\n# Problem input\nto_be_sorted = \"[0, 2, 6, 3, 8, 7, 1, 1, 6, 7, 7, 7, 7, 9, 3, 0, 1, 7, 9, 1, 3, 5, 1, 3, 6, 4, 5, 4, 7, 3, 5, 7]\""
        },
        {
            "comment": "This code retrieves the Graph of Operations (gop), configures a language model (lm) using config.json, creates a Controller object (ctrl) with the necessary components, and runs the controller to generate output graphs \"output_cot.json\" and \"output_got.json\". The final thought states' scores in the output graphs indicate the number of errors in the sorted list. Read the documentation for more detailed information on the framework's individual modules.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/README.md\":84-115",
            "content": "# Retrieve the Graph of Operations\ngop = got()\n# Configure the Language Model (Assumes config.json is in the current directory with OpenAI API key)\nlm = language_models.ChatGPT(\"config.json\", model_name=\"chatgpt\")\n# Create the Controller\nctrl = controller.Controller(\n  lm, \n  gop, \n  SortingPrompter(), \n  SortingParser(),\n  # The following dictionary is used to configure the initial thought state\n  {\n    \"original\": to_be_sorted,\n    \"current\": \"\",\n    \"phase\": 0,\n    \"method\": \"got\"\n  }\n)\n# Run the Controller and generate the output graph\nctrl.run()\nctrl.output_graph(\"output_got.json\")\n```\nYou can compare the two results by inspecting the output graphs `output_cot.json` and `output_got.json`.  \nThe final thought states' scores indicate the number of errors in the sorted list.\n## Documentation\nThe paper gives a high-level overview of the framework and its components.  \nIn order to understand the framework in more detail, you can read the documentation of the individual modules.  \nEspecially the [Controller](grap"
        },
        {
            "comment": "This code provides instructions on understanding and utilizing the framework, mentioning the importance of documentation for easy comprehension. It highlights the examples directory containing real-world problem solutions as a learning resource, with each example having a detailed README file. Additionally, it explains how to run the examples directly from the main directory and mentions that results will be stored in respective sub-directories. Lastly, it informs about running experiments from the paper through the examples directory.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/README.md\":115-132",
            "content": "h_of_thoughts/controller/README.md) and [Operations](graph_of_thoughts/operations/README.md) modules are important for understanding how to make the most out of the framework.  \nWe took extra care to fully document the code, so that you can easily understand how it works and how to extend it.\n## Examples\nThe [examples](examples) directory contains several examples of problems that can be solved using the framework, including the ones presented in the paper.  \nIt is a great starting point for learning how to use the framework to solve real problems.  \nEach example contains a `README.md` file with instructions on how to run it and play with it. The code is fully documented and should be easy to follow.\nYou can also run the examples straight from the main directory. Note that the results will be stored in the respective examples sub-directory.\nTry for instance:\n```bash\npython -m examples.sorting.sorting_032\npython -m examples.keyword_counting.keyword_counting\n```\n## Paper Results\nYou can run the experiments from the paper by following the instructions in the [examples](examples) directory.  "
        },
        {
            "comment": "The code provides instructions to access the project's results, suggests using the 'paper' directory for inspection and replotting, encourages starring the repository if valuable, offers contact information for questions or feedback, and recommends citing the provided reference when using the work in other projects.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/README.md\":133-149",
            "content": "However, if you just want to inspect and replot the results, you can use the [paper](paper) directory.\n## Citations\nIf you find this repository valuable, please give it a star!  \nGot any questions or feedback? Feel free to reach out to [nils.blach@inf.ethz.ch](mailto:nils.blach@inf.ethz.ch) or open an issue.  \nUsing this in your work? Please reference us using the provided citation:\n```bibtex\n@misc{besta2023got,\n  title = {{Graph of Thoughts: Solving Elaborate Problems with Large Language Models}},\n  author = {Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Podstawski, Micha{\\l} and Niewiadomski, Hubert and Nyczyk, Piotr and Hoefler, Torsten},\n  year = 2023,\n  eprinttype = {arXiv},\n  eprint = {2308.09687}\n}\n```"
        }
    ]
}