{
    "summary": "The comments describe operations that preserve valid thoughts from predecessors, with Comment A introducing an abstract base class for Graph of Thoughts operations and Comment B focusing on the GroundTruth operation in a code context.",
    "details": [
        {
            "comment": "This code defines an abstract base class for operations in the Graph of Thoughts system. It includes an OperationType Enum representing unique operation identifiers and outlines the interface for all operations. This base class will be used to create concrete implementations of different types of operations within the system.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":0-39",
            "content": "# Copyright (c) 2023 ETH Zurich.\n#                    All rights reserved.\n#\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n#\n# main author: Nils Blach\nfrom __future__ import annotations\nimport logging\nfrom enum import Enum\nfrom typing import List, Iterator, Dict, Callable, Union\nfrom abc import ABC, abstractmethod\nimport itertools\nfrom graph_of_thoughts.operations.thought import Thought\nfrom graph_of_thoughts.language_models import AbstractLanguageModel\nfrom graph_of_thoughts.prompter import Prompter\nfrom graph_of_thoughts.parser import Parser\nclass OperationType(Enum):\n    \"\"\"\n    Enum to represent different operation types that can be used as unique identifiers.\n    \"\"\"\n    score: int = 0\n    validate_and_improve: int = 1\n    generate: int = 2\n    improve: int = 3\n    aggregate: int = 4\n    keep_best_n: int = 5\n    keep_valid: int = 6\n    ground_truth_evaluator: int = 7\n    selector: int = 8\nclass Operation(ABC):\n    \"\"\"\n    Abstract base class that defines the interface for all operations."
        },
        {
            "comment": "Initializes a new Operation instance with a unique ID and empty predecessors and successors. The operation can be executed if all its predecessors have been executed. Aggregates thoughts from predecessors to return all thoughts from them.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":40-70",
            "content": "    \"\"\"\n    _ids: Iterator[int] = itertools.count(0)\n    operation_type: OperationType = None\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes a new Operation instance with a unique id, and empty predecessors and successors.\n        \"\"\"\n        self.logger: logging.Logger = logging.getLogger(self.__class__.__name__)\n        self.id: int = next(Operation._ids)\n        self.predecessors: List[Operation] = []\n        self.successors: List[Operation] = []\n        self.executed: bool = False\n    def can_be_executed(self) -> bool:\n        \"\"\"\n        Checks if the operation can be executed based on its predecessors.\n        :return: True if all predecessors have been executed, False otherwise.\n        :rtype: bool\n        \"\"\"\n        return all(predecessor.executed for predecessor in self.predecessors)\n    def get_previous_thoughts(self) -> List[Thought]:\n        \"\"\"\n        Iterates over all predecessors and aggregates their thoughts.\n        :return: A list of all thoughts from the predecessors.\n        :rtype: List[Thought]"
        },
        {
            "comment": "This code defines an Operation class with methods to add predecessors and successors, ensuring proper relationships are updated. The execute method executes the operation after all predecessors have been executed.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":71-104",
            "content": "        \"\"\"\n        previous_thoughts: List[Thought] = [\n            thought\n            for predecessor in self.predecessors\n            for thought in predecessor.get_thoughts()\n        ]\n        return previous_thoughts\n    def add_predecessor(self, operation: Operation) -> None:\n        \"\"\"\n        Add a preceding operation and update the relationships.\n        :param operation: The operation to be set as a predecessor.\n        :type operation: Operation\n        \"\"\"\n        self.predecessors.append(operation)\n        operation.successors.append(self)\n    def add_successor(self, operation: Operation) -> None:\n        \"\"\"\n        Add a succeeding operation and update the relationships.\n        :param operation: The operation to be set as a successor.\n        :type operation: Operation\n        \"\"\"\n        self.successors.append(operation)\n        operation.predecessors.append(self)\n    def execute(\n        self, lm: AbstractLanguageModel, prompter: Prompter, parser: Parser, **kwargs\n    ) -> None:\n        \"\"\"\n        Execute the operation, assuring that all predecessors have been executed."
        },
        {
            "comment": "The code defines a class with an abstract method for executing operations, requiring a language model (AbstractLanguageModel), prompter (Prompter), and parser (Parser). The class checks if all predecessors have been executed before execution, logs information during execution, marks itself as executed upon completion.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":106-129",
            "content": "        :param lm: The language model to be used.\n        :type lm: AbstractLanguageModel\n        :param prompter: The prompter for crafting prompts.\n        :type prompter: Prompter\n        :param parser: The parser for parsing responses.\n        :type parser: Parser\n        :param kwargs: Additional parameters for execution.\n        :raises AssertionError: If not all predecessors have been executed.\n        \"\"\"\n        assert self.can_be_executed(), \"Not all predecessors have been executed\"\n        self.logger.info(\n            \"Executing operation %d of type %s\", self.id, self.operation_type\n        )\n        self._execute(lm, prompter, parser, **kwargs)\n        self.logger.debug(\"Operation %d executed\", self.id)\n        self.executed = True\n    @abstractmethod\n    def _execute(\n        self, lm: AbstractLanguageModel, prompter: Prompter, parser: Parser, **kwargs\n    ) -> None:\n        \"\"\"\n        Abstract method for the actual execution of the operation.\n        This should be implemented in derived classes."
        },
        {
            "comment": "This code defines an abstract class \"Operation\" with a method to get associated thoughts and a concrete class \"Score\" that inherits from it. The Score class takes parameters like num_samples, combined_scoring, and scoring_function for scoring thoughts. The get_thoughts method must be implemented in derived classes.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":131-167",
            "content": "        :param lm: The language model to be used.\n        :type lm: AbstractLanguageModel\n        :param prompter: The prompter for crafting prompts.\n        :type prompter: Prompter\n        :param parser: The parser for parsing responses.\n        :type parser: Parser\n        :param kwargs: Additional parameters for execution.\n        \"\"\"\n        pass\n    @abstractmethod\n    def get_thoughts(self) -> List[Thought]:\n        \"\"\"\n        Abstract method to retrieve the thoughts associated with the operation.\n        This should be implemented in derived classes.\n        :return: List of associated thoughts.\n        :rtype: List[Thought]\n        \"\"\"\n        pass\nclass Score(Operation):\n    \"\"\"\n    Operation to score thoughts.\n    \"\"\"\n    operation_type: OperationType = OperationType.score\n    def __init__(\n        self,\n        num_samples: int = 1,\n        combined_scoring: bool = False,\n        scoring_function: Callable[\n            [Union[List[Dict], Dict]], Union[List[float], float]\n        ] = None,\n    ) -> None:"
        },
        {
            "comment": "This code defines a class for a Score operation that takes a specified number of samples, whether to score thoughts individually or combined, and a scoring function (defaulting to None). It initializes the operation with these parameters and returns the associated scored thoughts.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":168-191",
            "content": "        \"\"\"\n        Initializes a new Score operation.\n        :param num_samples: Number of samples to use for scoring. Defaults to 1.\n        :type num_samples: int\n        :param combined_scoring: Whether to score all thoughts together or individually. Defaults to False.\n        :type combined_scoring: bool\n        :param scoring_function: A function to score thoughts (if not using LM). Defaults to None.\n        :type scoring_function: Takes a list of thought states or a single thought state and\n                                returns a list of scores or a single score.\n        \"\"\"\n        super().__init__()\n        self.num_samples: int = num_samples\n        self.combined_scoring: bool = combined_scoring\n        self.thoughts: List[Thought] = []\n        self.scoring_function: Callable[\n            [Union[List[Dict], Dict]], Union[List[float], float]\n        ] = scoring_function\n    def get_thoughts(self) -> List[Thought]:\n        \"\"\"\n        Returns the thoughts associated with the operation.\n        :return: List of scored thoughts."
        },
        {
            "comment": "This code defines a method that executes a scoring operation on thoughts from predecessors. It first gets the previous thoughts and asserts that there is at least one predecessor. If combined scoring is used, it scores the thoughts together; otherwise, individually. The language model (LM) and prompter are used for prompting if a scoring function is not provided.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":192-217",
            "content": "        :rtype: List[Thought]\n        \"\"\"\n        return self.thoughts\n    def _execute(\n        self, lm: AbstractLanguageModel, prompter: Prompter, parser: Parser, **kwargs\n    ) -> None:\n        \"\"\"\n        Executes the scoring operation by scoring the thoughts from the predecessors.\n        If combined scoring is used, the thoughts are scored together, otherwise individually.\n        If a scoring function is provided, it is used, otherwise the LM is prompted.\n        :param lm: The language model to be used.\n        :type lm: AbstractLanguageModel\n        :param prompter: The prompter for crafting prompts.\n        :type prompter: Prompter\n        :param parser: The parser for parsing responses.\n        :type parser: Parser\n        :param kwargs: Additional parameters for execution.\n        :raises AssertionError: If operation has no predecessors.\n        \"\"\"\n        previous_thoughts: List[Thought] = self.get_previous_thoughts()\n        assert (\n            len(self.predecessors) > 0\n        ), \"Score operation needs at least one predecessor\""
        },
        {
            "comment": "This code calculates scores for each previous thought using either a scoring function or by generating prompts from the thoughts and querying a language model. The scores are then assigned to the respective thoughts, and new Thought objects are created with the updated scores before being added to the thoughts list.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":219-238",
            "content": "        if self.combined_scoring:\n            previous_thoughts_states = [thought.state for thought in previous_thoughts]\n            if self.scoring_function is not None:\n                self.logger.debug(\n                    \"Using scoring function %s to score states\", self.scoring_function\n                )\n                scores = self.scoring_function(previous_thoughts_states)\n            else:\n                prompt = prompter.score_prompt(previous_thoughts_states)\n                self.logger.debug(\"Prompt for LM: %s\", prompt)\n                responses = lm.get_response_texts(\n                    lm.query(prompt, num_responses=self.num_samples)\n                )\n                self.logger.debug(\"Responses from LM: %s\", responses)\n                scores = parser.parse_score_answer(previous_thoughts_states, responses)\n            for thought, score in zip(previous_thoughts, scores):\n                new_thought = Thought.from_thought(thought)\n                new_thought.score = score\n                self.thoughts.append(new_thought)"
        },
        {
            "comment": "This code handles scoring thoughts based on whether a scoring function is defined or not. If the scoring function is not defined, it prompts a language model (LM) to generate responses for each thought state and uses a parser to calculate scores from the LM's responses. The new score is then assigned to the thought object, and the thought is appended to the thoughts list.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":239-262",
            "content": "        else:\n            for thought in previous_thoughts:\n                new_thought = Thought.from_thought(thought)\n                if self.scoring_function is not None:\n                    self.logger.debug(\n                        \"Using scoring function %s to score state\",\n                        self.scoring_function,\n                    )\n                    score = self.scoring_function(thought.state)\n                else:\n                    prompt = prompter.score_prompt([thought.state])\n                    self.logger.debug(\"Prompt for LM: %s\", prompt)\n                    responses = lm.get_response_texts(\n                        lm.query(prompt, num_responses=self.num_samples)\n                    )\n                    self.logger.debug(\"Responses from LM: %s\", responses)\n                    score = parser.parse_score_answer([thought.state], responses)[0]\n                new_thought.score = score\n                self.thoughts.append(new_thought)\n        self.logger.info(\n            \"Score operation %d scored %d thoughts\","
        },
        {
            "comment": "This code defines a class called `ValidateAndImprove` that extends the `Operation` class. It is designed to validate and improve thoughts, with parameters for number of samples, whether to improve if not valid, number of tries before giving up, and a function to validate thoughts (optional). The operation type is specified as \"validate_and_improve\".",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":263-292",
            "content": "            self.id,\n            len(self.thoughts),\n        )\nclass ValidateAndImprove(Operation):\n    \"\"\"\n    Operation to validate and improve thoughts.\n    \"\"\"\n    operation_type: OperationType = OperationType.validate_and_improve\n    def __init__(\n        self,\n        num_samples: int = 1,\n        improve: bool = True,\n        num_tries: int = 3,\n        validate_function: Callable[[Dict], bool] = None,\n    ) -> None:\n        \"\"\"\n        Initializes a new ValidateAndImprove operation.\n        :param num_samples: Number of samples to use for validation. Defaults to 1.\n        :type num_samples: int\n        :param improve: Whether to improve the thought if it is not valid. Defaults to True.\n        :type improve: bool\n        :param num_tries: Number of tries to improve the thought before giving up. Defaults to 3.\n        :type num_tries: int\n        :param validate_function: A function to validate thoughts (if not using LM). Defaults to None.\n        :type validate_function: Takes a thought state and returns a boolean."
        },
        {
            "comment": "This code defines a class called `ValidateAndImprove` with attributes for the number of samples, whether to validate and improve thoughts, the number of tries, and a function to validate the thoughts. It also has methods to get final validated and improved thoughts, and execute validation and improvement using a language model.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":293-318",
            "content": "        \"\"\"\n        super().__init__()\n        self.num_samples: int = num_samples\n        self.improve: bool = improve\n        self.num_tries: int = num_tries\n        self.validate_function: Callable[[Dict], bool] = validate_function\n        self.thoughts: List[List[Thought]] = []\n    def get_thoughts(self) -> List[Thought]:\n        \"\"\"\n        Returns the list of final thoughts, after validation and improvement.\n        :return: List of final validated and improved thoughts.\n        :rtype: List[Thought]\n        \"\"\"\n        return [thought_list[-1] for thought_list in self.thoughts]\n    def _execute(\n        self, lm: AbstractLanguageModel, prompter: Prompter, parser: Parser, **kwargs\n    ) -> None:\n        \"\"\"\n        Executes the ValidateAndImprove operation by validating and improving the predecessors' thoughts.\n        If a validation function is provided, it is used, otherwise the LM is prompted.\n        If improvement is enabled, the LM is prompted to improve the thought, if it is not valid.\n        :param lm: The language model to be used."
        },
        {
            "comment": "This function gets the previous thoughts, checks that it has at least one predecessor, then iterates through the previous thoughts. It creates a new thought from each previous thought and enters a loop where it validates the current thought's state using a validate function.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":319-343",
            "content": "        :type lm: AbstractLanguageModel\n        :param prompter: The prompter for crafting prompts.\n        :type prompter: Prompter\n        :param parser: The parser for parsing responses.\n        :type parser: Parser\n        :param kwargs: Additional parameters for execution.\n        :raises AssertionError: If operation has no predecessors.\n        \"\"\"\n        previous_thoughts: List[Thought] = self.get_previous_thoughts()\n        assert (\n            len(self.predecessors) > 0\n        ), \"ValidateAndImprove operation needs at least one predecessor\"\n        for thought in previous_thoughts:\n            thought_list = []\n            current_thought = Thought.from_thought(thought)\n            current_try = 0\n            while True:\n                if self.validate_function is not None:\n                    self.logger.debug(\n                        \"Using validate function %s to score states\",\n                        self.validate_function,\n                    )\n                    valid = self.validate_function(current_thought.state)"
        },
        {
            "comment": "Code block retrieves a prompt from prompter, then uses it to get responses from a language model (LM). It validates the response, updates the current thought's validation status and adds it to the thought list. If conditions met, breaks out of the loop.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":344-365",
            "content": "                else:\n                    prompt = prompter.validation_prompt(**current_thought.state)\n                    self.logger.debug(\"Prompt for LM: %s\", prompt)\n                    responses = lm.get_response_texts(\n                        lm.query(prompt, num_responses=self.num_samples)\n                    )\n                    self.logger.debug(\"Responses from LM: %s\", responses)\n                    valid = parser.parse_validation_answer(\n                        current_thought.state, responses\n                    )\n                current_thought.valid = valid\n                thought_list.append(current_thought)\n                if (\n                    not self.improve\n                    or current_thought.valid\n                    or current_try >= self.num_tries\n                ):\n                    break\n                improve_prompt = prompter.improve_prompt(**current_thought.state)\n                self.logger.debug(\"Prompt for LM: %s\", improve_prompt)\n                responses = lm.get_response_texts("
        },
        {
            "comment": "This code defines an operation class \"Generate\" for generating thoughts using a language model (LM). It iteratively improves and validates each thought until it reaches the specified number of valid thoughts. Each thought is stored in the \"thoughts\" list. The \"Validate and improve\" operation creates new valid thoughts from previous invalid ones, appending them to the \"thoughts\" list.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":366-398",
            "content": "                    lm.query(improve_prompt, num_responses=1)\n                )\n                self.logger.debug(\"Responses from LM: %s\", responses)\n                state_update = parser.parse_improve_answer(\n                    current_thought.state, responses\n                )\n                current_thought = Thought({**current_thought.state, **state_update})\n                current_try += 1\n            self.thoughts.append(thought_list)\n        self.logger.info(\n            \"Validate and improve operation %d created %d valid thoughts from %d previous thoughts\",\n            self.id,\n            len(\n                [\n                    thought_list[-1]\n                    for thought_list in self.thoughts\n                    if thought_list[-1].valid\n                ]\n            ),\n            len(previous_thoughts),\n        )\nclass Generate(Operation):\n    \"\"\"\n    Operation to generate thoughts.\n    \"\"\"\n    operation_type: OperationType = OperationType.generate\n    def __init__(\n        self, num_branches_prompt: int = 1, num_branches_response: int = 1"
        },
        {
            "comment": "This code defines a class for generating thoughts, with parameters for the number of responses per prompt and the language model used. It initializes these parameters, stores generated thoughts in a list, and provides methods to retrieve them. The `_execute` method is responsible for generating thoughts using a language model, prompter, and parser.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":399-426",
            "content": "    ) -> None:\n        \"\"\"\n        Initializes a new Generate operation.\n        :param num_branches_prompt: Number of responses that each prompt should generate (passed to prompter). Defaults to 1.\n        :type num_branches_prompt: int\n        :param num_branches_response: Number of responses the LM should generate for each prompt. Defaults to 1.\n        :type num_branches_response: int\n        \"\"\"\n        super().__init__()\n        self.num_branches_prompt: int = num_branches_prompt\n        self.num_branches_response: int = num_branches_response\n        self.thoughts: List[Thought] = []\n    def get_thoughts(self) -> List[Thought]:\n        \"\"\"\n        Returns the thoughts associated with the operation.\n        :return: List of generated thoughts.\n        :rtype: List[Thought]\n        \"\"\"\n        return self.thoughts\n    def _execute(\n        self, lm: AbstractLanguageModel, prompter: Prompter, parser: Parser, **kwargs\n    ) -> None:\n        \"\"\"\n        Executes the Generate operation by generating thoughts from the predecessors."
        },
        {
            "comment": "This function generates thoughts by using a language model (LM) with the predecessor's thought states as prompts. If there are no predecessors, it uses kwargs as a base state to generate thoughts. It then parses and logs the generated prompt for the LM.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":427-450",
            "content": "        The thoughts are generated by prompting the LM with the predecessors' thought states.\n        If there are no predecessors, the kwargs are used as a base state.\n        :param lm: The language model to be used.\n        :type lm: AbstractLanguageModel\n        :param prompter: The prompter for crafting prompts.\n        :type prompter: Prompter\n        :param parser: The parser for parsing responses.\n        :type parser: Parser\n        :param kwargs: Additional parameters for execution.\n        \"\"\"\n        previous_thoughts: List[Thought] = self.get_previous_thoughts()\n        if len(previous_thoughts) == 0 and len(self.predecessors) > 0:\n            return\n        if len(previous_thoughts) == 0:\n            # no predecessors, use kwargs as base state\n            previous_thoughts = [Thought(state=kwargs)]\n        for thought in previous_thoughts:\n            base_state = thought.state\n            prompt = prompter.generate_prompt(self.num_branches_prompt, **base_state)\n            self.logger.debug(\"Prompt for LM: %s\", prompt)"
        },
        {
            "comment": "This code generates responses from a language model, parses them using a parser, and appends new thoughts to the thoughts list. If more thoughts are created than expected based on prompt and response numbers, a warning is logged.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":451-475",
            "content": "            responses = lm.get_response_texts(\n                lm.query(prompt, num_responses=self.num_branches_response)\n            )\n            self.logger.debug(\"Responses from LM: %s\", responses)\n            for new_state in parser.parse_generate_answer(base_state, responses):\n                new_state = {**base_state, **new_state}\n                self.thoughts.append(Thought(new_state))\n                self.logger.debug(\n                    \"New thought %d created with state %s\",\n                    self.thoughts[-1].id,\n                    self.thoughts[-1].state,\n                )\n        if (\n            len(self.thoughts)\n            > self.num_branches_prompt\n            * self.num_branches_response\n            * len(previous_thoughts)\n            and self.num_branches_prompt > 0\n        ):\n            self.logger.warning(\n                \"Generate operation %d created more thoughts than expected\",\n                self.id,\n            )\n        self.logger.info(\n            \"Generate operation %d created %d new thoughts\", self.id, len(self.thoughts)"
        },
        {
            "comment": "The code defines a class \"Improve\" which represents an operation to enhance thoughts. It initializes a new Improve operation and gets the associated thoughts after improvement. The \"_execute\" method executes the operation by improving the predecessor's thoughts using language model (LM) prompts.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":476-512",
            "content": "        )\nclass Improve(Operation):\n    \"\"\"\n    Operation to improve thoughts.\n    \"\"\"\n    operation_type: OperationType = OperationType.improve\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes a new Improve operation.\n        \"\"\"\n        super().__init__()\n        self.thoughts: List[Thought] = []\n    def get_thoughts(self) -> List[Thought]:\n        \"\"\"\n        Returns the thoughts associated with the operation after improvement.\n        :return: List of improved thoughts.\n        :rtype: List[Thought]\n        \"\"\"\n        return self.thoughts\n    def _execute(\n        self, lm: AbstractLanguageModel, prompter: Prompter, parser: Parser, **kwargs\n    ) -> None:\n        \"\"\"\n        Executes the Improve operation by improving the predecessors' thoughts.\n        The thoughts are improved by prompting the LM with the predecessors' thought states.\n        :param lm: The language model to be used.\n        :type lm: AbstractLanguageModel\n        :param prompter: The prompter for crafting prompts.\n        :type prompter: Prompter"
        },
        {
            "comment": "This code defines two classes: \"Improve\" and \"Aggregate\", which are subclasses of the \"Operation\" class. The \"Improve\" operation retrieves previous thoughts, improves their prompts using a prompter and language model (LM), gets response texts, parses the responses using a parser, and appends the updated thoughts to the list of thoughts for the current operation. The \"Aggregate\" operation also exists but has no implementation shown in this code snippet.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":513-536",
            "content": "        :param parser: The parser for parsing responses.\n        :type parser: Parser\n        :param kwargs: Additional parameters for execution.\n        :raises AssertionError: If operation has no predecessors.\n        \"\"\"\n        previous_thoughts: List[Thought] = self.get_previous_thoughts()\n        assert len(self.predecessors) > 0, \"Needs at least one predecessor\"\n        for thought in previous_thoughts:\n            improve_prompt = prompter.improve_prompt(**thought.state)\n            self.logger.debug(\"Prompt for LM: %s\", improve_prompt)\n            responses = lm.get_response_texts(lm.query(improve_prompt, num_responses=1))\n            self.logger.debug(\"Responses from LM: %s\", responses)\n            state_update = parser.parse_improve_answer(thought.state, responses)\n            self.thoughts.append(Thought({**thought.state, **state_update}))\n        self.logger.info(\n            \"Improve operation %d improved %d thoughts\", self.id, len(self.thoughts)\n        )\nclass Aggregate(Operation):\n    \"\"\""
        },
        {
            "comment": "This code defines an Aggregate operation class that initializes a new Aggregate operation and gets the associated thoughts after aggregation. It also includes a method to execute the operation by prompting the language model with predecessors' thought states for aggregation.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":537-567",
            "content": "    Operation to aggregate thoughts.\n    \"\"\"\n    operation_type: OperationType = OperationType.aggregate\n    def __init__(self, num_responses: int = 1) -> None:\n        \"\"\"\n        Initializes a new Aggregate operation.\n        :param num_responses: Number of responses to use for aggregation. Defaults to 1.\n        :type num_responses: int\n        \"\"\"\n        super().__init__()\n        self.thoughts: List[Thought] = []\n        self.num_responses: int = num_responses\n    def get_thoughts(self) -> List[Thought]:\n        \"\"\"\n        Returns the thoughts associated with the operation after aggregation.\n        :return: List of aggregated thoughts.\n        :rtype: List[Thought]\n        \"\"\"\n        return self.thoughts\n    def _execute(\n        self, lm: AbstractLanguageModel, prompter: Prompter, parser: Parser, **kwargs\n    ) -> None:\n        \"\"\"\n        Executes the Aggregate operation by aggregating the predecessors' thoughts.\n        The thoughts are aggregated by prompting the LM with the predecessors' thought states."
        },
        {
            "comment": "This code is a part of an operation class in Python. It checks if the operation has at least one predecessor and retrieves the previous thoughts from it. Then, it sorts the previous thoughts based on their score and constructs a prompt for aggregation using the prompter. Finally, it stores the states of the previous thoughts.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":569-593",
            "content": "        :param lm: The language model to be used.\n        :type lm: AbstractLanguageModel\n        :param prompter: The prompter for crafting prompts.\n        :type prompter: Prompter\n        :param parser: The parser for parsing responses.\n        :type parser: Parser\n        :param kwargs: Additional parameters for execution.\n        :raises AssertionError: If operation has no predecessors.\n        \"\"\"\n        assert (\n            len(self.predecessors) >= 1\n        ), \"Aggregate operation must have at least one predecessor\"\n        previous_thoughts: List[Thought] = self.get_previous_thoughts()\n        if len(previous_thoughts) == 0:\n            return\n        # applied in order of score\n        base_state: Dict = {}\n        for thought in sorted(previous_thoughts, key=lambda thought: thought.score):\n            base_state = {**base_state, **thought.state}\n        previous_thought_states = [thought.state for thought in previous_thoughts]\n        prompt = prompter.aggregation_prompt(previous_thought_states)"
        },
        {
            "comment": "The code defines a class `KeepBestN` that represents an operation to keep the best N thoughts from predecessors based on their score. The `__init__` method initializes a new `KeepBestN` object with the maximum number of thoughts to keep and whether higher scores are better.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":595-626",
            "content": "        self.logger.debug(\"Prompt for LM: %s\", prompt)\n        responses = lm.get_response_texts(\n            lm.query(prompt, num_responses=self.num_responses)\n        )\n        self.logger.debug(\"Responses from LM: %s\", responses)\n        parsed = parser.parse_aggregation_answer(previous_thought_states, responses)\n        if isinstance(parsed, dict):\n            parsed = [parsed]\n        for new_state in parsed:\n            self.thoughts.append(Thought({**base_state, **new_state}))\nclass KeepBestN(Operation):\n    \"\"\"\n    Operation to keep the best N thoughts from predecessors based on their score.\n    \"\"\"\n    operation_type: OperationType = OperationType.keep_best_n\n    def __init__(self, n: int, higher_is_better: bool = True) -> None:\n        \"\"\"\n        Initializes a new KeepBestN operation.\n        :param n: Maximum number of thoughts to keep.\n        :type n: int\n        :param higher_is_better: Whether higher scores are better. Defaults to True.\n        :type higher_is_better: bool\n        :raises AssertionError: If `n` is not greater than zero."
        },
        {
            "comment": "Class `KeepBestN` initializes its attributes and checks the minimum number of thoughts to keep, then provides a method `get_best_n()` that returns the top N thoughts based on their scores. It raises `AssertionError` if all predecessors haven't been executed or if not all thoughts have been scored.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":627-654",
            "content": "        \"\"\"\n        super().__init__()\n        self.n: int = n\n        assert self.n > 0, \"KeepBestN operation must keep at least one thought\"\n        self.higher_is_better: bool = higher_is_better\n        self.thoughts: List[Thought] = []\n    def get_best_n(self) -> List[Thought]:\n        \"\"\"\n        Returns the best N thoughts from the predecessors based on their score.\n        :return: List of best N thoughts.\n        :rtype: List[Thought]\n        :raises AssertionError: If not all predecessors have been executed.\n        :raises AssertionError: If not all thoughts have been scored.\n        \"\"\"\n        previous_thoughts: List[Thought] = self.get_previous_thoughts()\n        assert all(\n            previous_thought.scored for previous_thought in previous_thoughts\n        ), \"Not all thoughts have been scored\"\n        try:\n            return sorted(\n                previous_thoughts,\n                key=lambda thought: thought.score,\n                reverse=self.higher_is_better,\n            )[: self.n]\n        except:"
        },
        {
            "comment": "This code defines a `KeepBestN` operation that keeps the top N thoughts from predecessors based on their scores. It logs an error message with previous operation details and previous thoughts' scores, and returns the sorted list of thoughts. The class has methods to access kept thoughts and execute the operation using given language model, prompter, and parser.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":655-682",
            "content": "            self.logger.error(\"Error in KeepBestN operation\")\n            self.logger.error(\n                \"Previous operation: %s\", [op.id for op in self.predecessors]\n            )\n            self.logger.error(\"Previous thoughts: %s\", previous_thoughts)\n            self.logger.error(\n                \"Scores: %s\", [thought.score for thought in previous_thoughts]\n            )\n            return sorted(\n                [i for i in previous_thoughts if isinstance(i.score, float)],\n                key=lambda thought: thought.score,\n                reverse=self.higher_is_better,\n            )[: self.n]\n    def get_thoughts(self) -> List[Thought]:\n        \"\"\"\n        Returns the thoughts kept by the operation.\n        :return: List of kept thoughts.\n        :rtype: List[Thought]\n        \"\"\"\n        return self.thoughts\n    def _execute(\n        self, lm: AbstractLanguageModel, prompter: Prompter, parser: Parser, **kwargs\n    ) -> None:\n        \"\"\"\n        Executes the KeepBestN operation by keeping the best N thoughts from the predecessors according to their score."
        },
        {
            "comment": "The code defines a function for the KeepBestN operation, which requires at least one predecessor, and raises AssertionError if any conditions are not met. It retrieves thoughts from predecessors and logs information about the kept thoughts.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":684-707",
            "content": "        :param lm: The language model to be used.\n        :type lm: AbstractLanguageModel\n        :param prompter: The prompter for crafting prompts.\n        :type prompter: Prompter\n        :param parser: The parser for parsing responses.\n        :type parser: Parser\n        :param kwargs: Additional parameters for execution.\n        :raises AssertionError: If operation has no predecessors.\n        :raises AssertionError: If not all predecessors have been executed.\n        :raises AssertionError: If not all thoughts have been scored.\n        \"\"\"\n        assert (\n            len(self.predecessors) >= 1\n        ), \"KeepBestN operation must have at least one predecessor\"\n        self.thoughts = [Thought.from_thought(thought) for thought in self.get_best_n()]\n        for thought in self.thoughts:\n            self.logger.debug(\n                \"Thought %d with state %s kept\", thought.id, thought.state\n            )\n        self.logger.info(\n            \"KeepBestN operation %d kept %d thoughts\", self.id, len(self.thoughts)"
        },
        {
            "comment": "The `KeepValid` operation keeps valid thoughts from predecessors and returns them. It also preserves unvalidated thoughts. This class initializes a new KeepValid operation and provides methods for retrieving the kept thoughts and executing the operation using a language model, prompter, and parser.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":708-745",
            "content": "        )\nclass KeepValid(Operation):\n    \"\"\"\n    Operation to keep valid thoughts from predecessors.\n    \"\"\"\n    operation_type: OperationType = OperationType.keep_valid\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes a new KeepValid operation.\n        \"\"\"\n        super().__init__()\n        self.thoughts: List[Thought] = []\n    def get_thoughts(self) -> List[Thought]:\n        \"\"\"\n        Returns the thoughts kept by the operation.\n        :return: List of kept thoughts.\n        :rtype: List[Thought]\n        \"\"\"\n        return self.thoughts\n    def _execute(\n        self, lm: AbstractLanguageModel, prompter: Prompter, parser: Parser, **kwargs\n    ) -> None:\n        \"\"\"\n        Executes the KeepValid operation by keeping the valid thoughts from the predecessors.\n        Keeps unvalidated thoughts as well.\n        :param lm: The language model to be used.\n        :type lm: AbstractLanguageModel\n        :param prompter: The prompter for crafting prompts.\n        :type prompter: Prompter\n        :param parser: The parser for parsing responses."
        },
        {
            "comment": "The code defines two classes: \"KeepValid\" and \"GroundTruth\". The KeepValid class is an operation that requires at least one predecessor. It collects thoughts from previous operations (excluding those that are not valid or already valid) into a list called \"self.thoughts\". If there are any unvalidated thoughts, it logs a warning. Then, it logs debug and info messages for each thought in the list, including its ID and state, as well as the total number of thoughts kept. The GroundTruth class is an operation that uses a ground truth evaluator to assess if thoughts correctly solve the problem.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":746-777",
            "content": "        :type parser: Parser\n        :param kwargs: Additional parameters for execution.\n        :raises AssertionError: If operation has no predecessors.\n        \"\"\"\n        assert (\n            len(self.predecessors) >= 1\n        ), \"KeepValid operation must have at least one predecessor\"\n        self.thoughts: List[Thought] = [\n            Thought.from_thought(thought)\n            for thought in self.get_previous_thoughts()\n            if not thought.validated or thought.valid\n        ]\n        if any(not thought.validated for thought in self.thoughts):\n            self.logger.warning(\n                \"KeepValid operation %d has unvalidated thoughts\", self.id\n            )\n        for thought in self.thoughts:\n            self.logger.debug(\n                \"Thought %d with state %s kept\", thought.id, thought.state\n            )\n        self.logger.info(\n            \"KeepValid operation %d kept %d thoughts\", self.id, len(self.thoughts)\n        )\nclass GroundTruth(Operation):\n    \"\"\"\n    Operation to evaluate if thoughts correctly solve the problem, using a ground truth evaluator"
        },
        {
            "comment": "This code defines a class for the GroundTruth operation, which initializes with a ground truth evaluator function. The operation evaluates predecessors' thoughts using this function and stores them in a list of thoughts. The get_thoughts method returns these evaluated thoughts.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":778-806",
            "content": "    \"\"\"\n    operation_type: OperationType = OperationType.ground_truth_evaluator\n    def __init__(self, ground_truth_evaluator: Callable[[Dict], bool]) -> None:\n        \"\"\"\n        Initializes a new GroundTruth operation.\n        :param ground_truth_evaluator: A function to evaluate if a thought solves the problem.\n        :type ground_truth_evaluator: A function that takes a thought state and returns a boolean.\n        \"\"\"\n        super().__init__()\n        self.ground_truth_evaluator: Callable[[Dict], bool] = ground_truth_evaluator\n        self.thoughts: List[Thought] = []\n    def get_thoughts(self) -> List[Thought]:\n        \"\"\"\n        Returns the thoughts associated with the operation.\n        :return: List of evaluated thoughts.\n        :rtype: List[Thought]\n        \"\"\"\n        return self.thoughts\n    def _execute(\n        self, lm: AbstractLanguageModel, prompter: Prompter, parser: Parser, **kwargs\n    ) -> None:\n        \"\"\"\n        Executes the GroundTruth operation by evaluating the predecessors' thoughts using the ground truth evaluator function."
        },
        {
            "comment": "This code is part of a class that implements the GroundTruth operation. It ensures that the operation has at least one predecessor and evaluates the thoughts generated by the previous operations. The evaluated thoughts are then added to the current operation's thoughts list, and their solved status is determined using the ground_truth_evaluator method. If any exceptions occur during the evaluation process, the solved status is set to False. Finally, an info message is logged indicating how many thoughts were evaluated and how many of them solved the problem.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":808-832",
            "content": "        :param lm: The language model to be used.\n        :type lm: AbstractLanguageModel\n        :param prompter: The prompter for crafting prompts.\n        :type prompter: Prompter\n        :param parser: The parser for parsing responses.\n        :type parser: Parser\n        :param kwargs: Additional parameters for execution.\n        :raises AssertionError: If operation has no predecessor.\n        \"\"\"\n        assert (\n            len(self.predecessors) >= 1\n        ), \"GroundTruth operation must have at least one predecessor\"\n        previous_thoughts: List[Thought] = self.get_previous_thoughts()\n        for thought in previous_thoughts:\n            new_thought = Thought.from_thought(thought)\n            try:\n                new_thought.solved = self.ground_truth_evaluator(new_thought.state)\n            except:\n                new_thought.solved = False\n            self.thoughts.append(new_thought)\n        self.logger.info(\n            \"GroundTruth operation %d evaluated %d thoughts and %d solved the problem\","
        },
        {
            "comment": "This code defines a Selector operation for the Graph of Thoughts, which selects thoughts from predecessors to be used in subsequent operations. The constructor takes a selector function that accepts a list of thoughts and returns a list of selected thoughts. The get_thoughts method returns the thoughts selected by the operation.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":833-863",
            "content": "            self.id,\n            len(self.thoughts),\n            len([thought for thought in self.thoughts if thought.solved]),\n        )\nclass Selector(Operation):\n    \"\"\"\n    Operation to select thoughts from predecessors.\n    Useful for separating thoughts to perform different, subsequent operations on them.\n    \"\"\"\n    operation_type: OperationType = OperationType.selector\n    def __init__(self, selector: Callable[[List[Thought]], List[Thought]]) -> None:\n        \"\"\"\n        Initializes a new Selector operation.\n        :param selector: A function to select thoughts from the predecessors' thoughts.\n        :type selector: A function that takes a list of thoughts and returns a list of thoughts.\n        \"\"\"\n        super().__init__()\n        self.selector: Callable[[List[Thought]], List[Thought]] = selector\n        self.thoughts: List[Thought] = []\n    def get_thoughts(self) -> List[Thought]:\n        \"\"\"\n        Returns the thoughts selected by the operation.\n        :return: List of selected thoughts.\n        :rtype: List[Thought]"
        },
        {
            "comment": "This code defines a Selector operation, which selects thoughts from predecessors using a provided selector function. If there are no predecessors, the function calls the selector with a thought containing the provided kwargs as state. The selected thoughts are then returned.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":864-889",
            "content": "        \"\"\"\n        return self.thoughts\n    def _execute(\n        self, lm: AbstractLanguageModel, prompter: Prompter, parser: Parser, **kwargs\n    ) -> None:\n        \"\"\"\n        Executes the Selector operation by selecting thoughts from the predecessors using the selector function.\n        If the Selector has no predecessors, the selector function is called with a thought containing the kwargs as state.\n        :param lm: The language model to be used.\n        :type lm: AbstractLanguageModel\n        :param prompter: The prompter for crafting prompts.\n        :type prompter: Prompter\n        :param parser: The parser for parsing responses.\n        :type parser: Parser\n        :param kwargs: Additional parameters for execution.\n        \"\"\"\n        previous_thoughts: List[Thought] = self.get_previous_thoughts()\n        if len(previous_thoughts) == 0:\n            previous_thoughts = [Thought(kwargs)]\n        self.thoughts = [\n            Thought.from_thought(thought)\n            for thought in self.selector(previous_thoughts)"
        },
        {
            "comment": "This code segment is logging the selection of thoughts by a selector operation. It iterates over each thought in the self.thoughts list, and logs their ID and state. Finally, it logs the total number of thoughts selected by this operation.",
            "location": "\"/media/root/Toshiba XG3/works/graph-of-thoughts/docs/src/graph_of_thoughts/operations/operations.py\":890-899",
            "content": "        ]\n        for thought in self.thoughts:\n            self.logger.debug(\n                \"Thought %d with state %s selected\", thought.id, thought.state\n            )\n        self.logger.info(\n            \"Selector operation %d selected %d thoughts\", self.id, len(self.thoughts)\n        )"
        }
    ]
}